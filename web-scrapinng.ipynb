{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12b10679-53d5-45b8-88fb-bf765e8ad74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "13f78d71-958c-4632-9361-b330da863470",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers={'User-Agent':'Mozilla/5.0 (Windows NT 6.3; Win 64 ; x64) Apple WeKit /537.36(KHTML , like Gecko) Chrome/80.0.3987.162 Safari/537.36'}\n",
    "webpage = requests.get('https://www.ambitionbox.com/list-of-companies?page=1',headers =headers ).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "298f4aad-edc9-47c9-b499-b9f7e0380365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lxml\n",
      "  Using cached lxml-6.0.2-cp313-cp313-win_amd64.whl.metadata (3.7 kB)\n",
      "Using cached lxml-6.0.2-cp313-cp313-win_amd64.whl (4.0 MB)\n",
      "Installing collected packages: lxml\n",
      "Successfully installed lxml-6.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install lxml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbdd97f2-de4a-425e-9790-3125ae9c0a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Python313\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62a69bc1-5d83-4db0-9546-d57ff343085f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lxml\n",
      "  Using cached lxml-6.0.2-cp313-cp313-win_amd64.whl.metadata (3.7 kB)\n",
      "Using cached lxml-6.0.2-cp313-cp313-win_amd64.whl (4.0 MB)\n",
      "Installing collected packages: lxml\n",
      "  Attempting uninstall: lxml\n",
      "    Found existing installation: lxml 6.0.2\n",
      "    Uninstalling lxml-6.0.2:\n",
      "      Successfully uninstalled lxml-6.0.2\n",
      "Successfully installed lxml-6.0.2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install lxml --upgrade --force-reinstall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f86ed25-1148-4b62-a6db-9985ce667ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(webpage, 'lxml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "abeef953-5109-415b-9a2f-a58e619b8ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Companies in India\n",
      "TCS\n",
      "Accenture\n",
      "Wipro\n",
      "Cognizant\n",
      "Capgemini\n",
      "HDFC Bank\n",
      "Infosys\n",
      "ICICI Bank\n",
      "HCLTech\n",
      "Tech Mahindra\n",
      "Genpact\n",
      "Teleperformance\n",
      "Axis Bank\n",
      "Concentrix Corporation\n",
      "Jio\n",
      "Amazon\n",
      "iEnergizer\n",
      "Reliance Retail\n",
      "IBM\n",
      "LTIMindtree\n"
     ]
    }
   ],
   "source": [
    "for i in soup.find_all('h2'):\n",
    "    print(i.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "634723e7-87bd-48fd-be9f-6133833aaa2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(soup.find_all('a',class_='companyCardWrapper__ActionWrapper'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ab1ea0b1-34b6-4c7c-b26f-5029bfecfd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "name=[]\n",
    "rating=[]\n",
    "reviews=[]\n",
    "ctype=[]\n",
    "hq=[]\n",
    "how_old=[]\n",
    "no_of_employee=[]\n",
    "\n",
    "for i in company:\n",
    "\n",
    "  name.append(i.find('h2').text.strip())\n",
    "  rating.append(i.find('p',class_='rating').text.strip())\n",
    "  reviews.append(i.find('a' , class_='review-count').text.strip())\n",
    "  ctype.append(i.find_all('p',class_='infoEntity')[0].text.strip())\n",
    "  hq.append(i.find_all('p',class_='infoEntity')[1].text.strip())\n",
    "  how_old.append(i.find_all('p',class_='infoEntity')[2].text.strip())\n",
    "  no_of_employee.append(i.find_all('p',class_='infoEntity')[3].text.strip())\n",
    "\n",
    "df=pd.DataFrame({'name':name,\n",
    "   'rating':rating,\n",
    "   'reviews':reviews,\n",
    "   'company_type':ctype,\n",
    "   'Head_Quarters':hq,\n",
    "   'Company_Age':how_old,\n",
    "   'No_of_Employee':no_of_employee,\n",
    "   })\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3478b1-898a-4cde-81d9-a9ae3271dddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creatting dataframe for all pages\n",
    "final=pd.DataFrame()\n",
    "for j in range(1,1001):\n",
    "  webpage=requests.get('https://www.ambitionbox.com/list-of-companies?page={}'.format(j)).text\n",
    "  soup=BeautifulSoup(webpage,'lxml')\n",
    "  company=soup.find_all('div',class_='company-content-wrapper')\n",
    "  name=[]\n",
    "  rating=[]\n",
    "  reviews=[]\n",
    "  ctype=[]\n",
    "  hq=[]\n",
    "  how_old=[]\n",
    "  no_of_employee=[]\n",
    "\n",
    "  for i in company:\n",
    "\n",
    "    try:\n",
    "       name.append(i.find('h2').text.strip())\n",
    "    except:\n",
    "       name.append(np.nan)\n",
    "\n",
    "    try:\n",
    "       rating.append(i.find('p',class_='rating').text.strip())\n",
    "    except:\n",
    "       rating.append(np.nan)\n",
    "   \n",
    "    try:\n",
    "\n",
    "      reviews.append(i.find('a' , class_='review-count').text.strip())\n",
    "    except:\n",
    "      reviews.append(np.nan)\n",
    "\n",
    "    try:\n",
    "\n",
    "      ctype.append(i.find_all('p',class_='infoEntity')[0].text.strip())\n",
    "    except:\n",
    "      ctype.append(np.nan)\n",
    "    try:\n",
    "\n",
    "      hq.append(i.find_all('p',class_='infoEntity')[1].text.strip())\n",
    "    except:\n",
    "      hq.append(np.nan)\n",
    "    \n",
    "    try:\n",
    "\n",
    "      how_old.append(i.find_all('p',class_='infoEntity')[2].text.strip())\n",
    "    except:\n",
    "      how_old.append(np.nan)\n",
    "    try:\n",
    "      no_of_employee.append(i.find_all('p',class_='infoEntity')[3].text.strip())\n",
    "    except:\n",
    "      no_of_employee.append(np.nan)\n",
    "    \n",
    "\n",
    "  df=pd.DataFrame({'name':name,\n",
    "    'rating':rating,\n",
    "    'reviews':reviews,\n",
    "    'company_type':ctype,\n",
    "    'Head_Quarters':hq,\n",
    "    'Company_Age':how_old,\n",
    "    'No_of_Employee':no_of_employee,\n",
    "    })\n",
    "  \n",
    "  final=final.append(df,ignore_index=True)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
